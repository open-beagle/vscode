{"version":3,"file":"textToHtmlTokenizer.js","sourceRoot":"file:///go/src/gitlab.wodcloud.com/cloud/vscode/lib/vscode/src","sources":["vs/editor/common/modes/textToHtmlTokenizer.ts"],"names":[],"mappings":"AAAA;;;gGAGgG;;;;;IAchG,MAAM,QAAQ,GAAgC;QAC7C,eAAe,EAAE,GAAG,EAAE,CAAC,qBAAU;QACjC,SAAS,EAAE,CAAC,MAAc,EAAE,MAAe,EAAE,KAAa,EAAE,WAAmB,EAAE,EAAE,CAAC,CAAA,GAAA,wBAAa,CAAA,eAAkB,MAAM,EAAE,KAAK,EAAE,WAAW,CAAC;KAC9I,CAAC;IAEF,SAAgB,gBAAgB,CAAC,IAAY,EAAE,sBAAmD,QAAQ;QACzG,OAAO,iBAAiB,CAAC,IAAI,EAAE,mBAAmB,IAAI,QAAQ,CAAC,CAAC;IACjE,CAAC;IAFD,4CAEC;IAED,SAAgB,kBAAkB,CAAC,IAAY,EAAE,cAA+B,EAAE,QAAkB,EAAE,WAAmB,EAAE,SAAiB,EAAE,OAAe,EAAE,OAAgB;QAC9K,IAAI,MAAM,GAAG,OAAO,CAAC;QACrB,IAAI,SAAS,GAAG,WAAW,CAAC;QAC5B,IAAI,aAAa,GAAG,CAAC,CAAC;QAEtB,KAAK,IAAI,UAAU,GAAG,CAAC,EAAE,UAAU,GAAG,cAAc,CAAC,QAAQ,EAAE,EAAE,UAAU,GAAG,UAAU,EAAE,UAAU,EAAE,EAAE;YACvG,MAAM,aAAa,GAAG,cAAc,CAAC,YAAY,CAAC,UAAU,CAAC,CAAC;YAE9D,IAAI,aAAa,IAAI,WAAW,EAAE;gBACjC,SAAS;aACT;YAED,IAAI,WAAW,GAAG,EAAE,CAAC;YAErB,OAAO,SAAS,GAAG,aAAa,IAAI,SAAS,GAAG,SAAS,EAAE,SAAS,EAAE,EAAE;gBACvE,MAAM,QAAQ,GAAG,IAAI,CAAC,UAAU,CAAC,SAAS,CAAC,CAAC;gBAE5C,QAAQ,QAAQ,EAAE;oBACjB;wBACC,IAAI,iBAAiB,GAAG,OAAO,GAAG,CAAC,SAAS,GAAG,aAAa,CAAC,GAAG,OAAO,CAAC;wBACxE,aAAa,IAAI,iBAAiB,GAAG,CAAC,CAAC;wBACvC,OAAO,iBAAiB,GAAG,CAAC,EAAE;4BAC7B,WAAW,IAAI,OAAO,CAAC,CAAC,CAAC,QAAQ,CAAC,CAAC,CAAC,GAAG,CAAC;4BACxC,iBAAiB,EAAE,CAAC;yBACpB;wBACD,MAAM;oBAEP;wBACC,WAAW,IAAI,MAAM,CAAC;wBACtB,MAAM;oBAEP;wBACC,WAAW,IAAI,MAAM,CAAC;wBACtB,MAAM;oBAEP;wBACC,WAAW,IAAI,OAAO,CAAC;wBACvB,MAAM;oBAEP;wBACC,WAAW,IAAI,OAAO,CAAC;wBACvB,MAAM;oBAEP,0BAAuB;oBACvB,+BAA6B;oBAC7B,oCAAkC;oBAClC;wBACC,WAAW,IAAI,QAAQ,CAAC;wBACxB,MAAM;oBAEP;wBACC,yEAAyE;wBACzE,WAAW,IAAI,QAAQ,CAAC;wBACxB,MAAM;oBAEP;wBACC,WAAW,IAAI,OAAO,CAAC,CAAC,CAAC,QAAQ,CAAC,CAAC,CAAC,GAAG,CAAC;wBACxC,MAAM;oBAEP;wBACC,WAAW,IAAI,MAAM,CAAC,YAAY,CAAC,QAAQ,CAAC,CAAC;iBAC9C;aACD;YAED,MAAM,IAAI,gBAAgB,cAAc,CAAC,cAAc,CAAC,UAAU,EAAE,QAAQ,CAAC,KAAK,WAAW,SAAS,CAAC;YAEvG,IAAI,aAAa,GAAG,SAAS,IAAI,SAAS,IAAI,SAAS,EAAE;gBACxD,MAAM;aACN;SACD;QAED,MAAM,IAAI,QAAQ,CAAC;QACnB,OAAO,MAAM,CAAC;IACf,CAAC;IAzED,gDAyEC;IAED,SAAS,iBAAiB,CAAC,IAAY,EAAE,mBAAgD;QACxF,IAAI,MAAM,GAAG,uCAAuC,CAAC;QACrD,IAAI,KAAK,GAAG,OAAO,CAAC,UAAU,CAAC,IAAI,CAAC,CAAC;QACrC,IAAI,YAAY,GAAG,mBAAmB,CAAC,eAAe,EAAE,CAAC;QACzD,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,GAAG,GAAG,KAAK,CAAC,MAAM,EAAE,CAAC,GAAG,GAAG,EAAE,CAAC,EAAE,EAAE;YACjD,IAAI,IAAI,GAAG,KAAK,CAAC,CAAC,CAAC,CAAC;YAEpB,IAAI,CAAC,GAAG,CAAC,EAAE;gBACV,MAAM,IAAI,OAAO,CAAC;aAClB;YAED,IAAI,kBAAkB,GAAG,mBAAmB,CAAC,SAAS,CAAC,IAAI,EAAE,IAAI,EAAE,YAAY,EAAE,CAAC,CAAC,CAAC;YACpF,uBAAU,CAAC,kBAAkB,CAAC,kBAAkB,CAAC,MAAM,EAAE,IAAI,CAAC,MAAM,CAAC,CAAC;YACtE,IAAI,UAAU,GAAG,IAAI,uBAAU,CAAC,kBAAkB,CAAC,MAAM,EAAE,IAAI,CAAC,CAAC;YACjE,IAAI,cAAc,GAAG,UAAU,CAAC,OAAO,EAAE,CAAC;YAE1C,IAAI,WAAW,GAAG,CAAC,CAAC;YACpB,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,IAAI,GAAG,cAAc,CAAC,QAAQ,EAAE,EAAE,CAAC,GAAG,IAAI,EAAE,CAAC,EAAE,EAAE;gBAChE,MAAM,IAAI,GAAG,cAAc,CAAC,YAAY,CAAC,CAAC,CAAC,CAAC;gBAC5C,MAAM,QAAQ,GAAG,cAAc,CAAC,YAAY,CAAC,CAAC,CAAC,CAAC;gBAChD,MAAM,IAAI,gBAAgB,IAAI,KAAK,OAAO,CAAC,MAAM,CAAC,IAAI,CAAC,SAAS,CAAC,WAAW,EAAE,QAAQ,CAAC,CAAC,SAAS,CAAC;gBAClG,WAAW,GAAG,QAAQ,CAAC;aACvB;YAED,YAAY,GAAG,kBAAkB,CAAC,QAAQ,CAAC;SAC3C;QAED,MAAM,IAAI,QAAQ,CAAC;QACnB,OAAO,MAAM,CAAC;IACf,CAAC","sourcesContent":["/*---------------------------------------------------------------------------------------------\n *  Copyright (c) Microsoft Corporation. All rights reserved.\n *  Licensed under the MIT License. See License.txt in the project root for license information.\n *--------------------------------------------------------------------------------------------*/\n\nimport { CharCode } from 'vs/base/common/charCode';\nimport * as strings from 'vs/base/common/strings';\nimport { IViewLineTokens, LineTokens } from 'vs/editor/common/core/lineTokens';\nimport { TokenizationResult2 } from 'vs/editor/common/core/token';\nimport { IState, LanguageId } from 'vs/editor/common/modes';\nimport { NULL_STATE, nullTokenize2 } from 'vs/editor/common/modes/nullMode';\n\nexport interface IReducedTokenizationSupport {\n\tgetInitialState(): IState;\n\ttokenize2(line: string, hasEOL: boolean, state: IState, offsetDelta: number): TokenizationResult2;\n}\n\nconst fallback: IReducedTokenizationSupport = {\n\tgetInitialState: () => NULL_STATE,\n\ttokenize2: (buffer: string, hasEOL: boolean, state: IState, deltaOffset: number) => nullTokenize2(LanguageId.Null, buffer, state, deltaOffset)\n};\n\nexport function tokenizeToString(text: string, tokenizationSupport: IReducedTokenizationSupport = fallback): string {\n\treturn _tokenizeToString(text, tokenizationSupport || fallback);\n}\n\nexport function tokenizeLineToHTML(text: string, viewLineTokens: IViewLineTokens, colorMap: string[], startOffset: number, endOffset: number, tabSize: number, useNbsp: boolean): string {\n\tlet result = `<div>`;\n\tlet charIndex = startOffset;\n\tlet tabsCharDelta = 0;\n\n\tfor (let tokenIndex = 0, tokenCount = viewLineTokens.getCount(); tokenIndex < tokenCount; tokenIndex++) {\n\t\tconst tokenEndIndex = viewLineTokens.getEndOffset(tokenIndex);\n\n\t\tif (tokenEndIndex <= startOffset) {\n\t\t\tcontinue;\n\t\t}\n\n\t\tlet partContent = '';\n\n\t\tfor (; charIndex < tokenEndIndex && charIndex < endOffset; charIndex++) {\n\t\t\tconst charCode = text.charCodeAt(charIndex);\n\n\t\t\tswitch (charCode) {\n\t\t\t\tcase CharCode.Tab:\n\t\t\t\t\tlet insertSpacesCount = tabSize - (charIndex + tabsCharDelta) % tabSize;\n\t\t\t\t\ttabsCharDelta += insertSpacesCount - 1;\n\t\t\t\t\twhile (insertSpacesCount > 0) {\n\t\t\t\t\t\tpartContent += useNbsp ? '&#160;' : ' ';\n\t\t\t\t\t\tinsertSpacesCount--;\n\t\t\t\t\t}\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase CharCode.LessThan:\n\t\t\t\t\tpartContent += '&lt;';\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase CharCode.GreaterThan:\n\t\t\t\t\tpartContent += '&gt;';\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase CharCode.Ampersand:\n\t\t\t\t\tpartContent += '&amp;';\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase CharCode.Null:\n\t\t\t\t\tpartContent += '&#00;';\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase CharCode.UTF8_BOM:\n\t\t\t\tcase CharCode.LINE_SEPARATOR:\n\t\t\t\tcase CharCode.PARAGRAPH_SEPARATOR:\n\t\t\t\tcase CharCode.NEXT_LINE:\n\t\t\t\t\tpartContent += '\\ufffd';\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase CharCode.CarriageReturn:\n\t\t\t\t\t// zero width space, because carriage return would introduce a line break\n\t\t\t\t\tpartContent += '&#8203';\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase CharCode.Space:\n\t\t\t\t\tpartContent += useNbsp ? '&#160;' : ' ';\n\t\t\t\t\tbreak;\n\n\t\t\t\tdefault:\n\t\t\t\t\tpartContent += String.fromCharCode(charCode);\n\t\t\t}\n\t\t}\n\n\t\tresult += `<span style=\"${viewLineTokens.getInlineStyle(tokenIndex, colorMap)}\">${partContent}</span>`;\n\n\t\tif (tokenEndIndex > endOffset || charIndex >= endOffset) {\n\t\t\tbreak;\n\t\t}\n\t}\n\n\tresult += `</div>`;\n\treturn result;\n}\n\nfunction _tokenizeToString(text: string, tokenizationSupport: IReducedTokenizationSupport): string {\n\tlet result = `<div class=\"monaco-tokenized-source\">`;\n\tlet lines = strings.splitLines(text);\n\tlet currentState = tokenizationSupport.getInitialState();\n\tfor (let i = 0, len = lines.length; i < len; i++) {\n\t\tlet line = lines[i];\n\n\t\tif (i > 0) {\n\t\t\tresult += `<br/>`;\n\t\t}\n\n\t\tlet tokenizationResult = tokenizationSupport.tokenize2(line, true, currentState, 0);\n\t\tLineTokens.convertToEndOffset(tokenizationResult.tokens, line.length);\n\t\tlet lineTokens = new LineTokens(tokenizationResult.tokens, line);\n\t\tlet viewLineTokens = lineTokens.inflate();\n\n\t\tlet startOffset = 0;\n\t\tfor (let j = 0, lenJ = viewLineTokens.getCount(); j < lenJ; j++) {\n\t\t\tconst type = viewLineTokens.getClassName(j);\n\t\t\tconst endIndex = viewLineTokens.getEndOffset(j);\n\t\t\tresult += `<span class=\"${type}\">${strings.escape(line.substring(startOffset, endIndex))}</span>`;\n\t\t\tstartOffset = endIndex;\n\t\t}\n\n\t\tcurrentState = tokenizationResult.endState;\n\t}\n\n\tresult += `</div>`;\n\treturn result;\n}\n"]}